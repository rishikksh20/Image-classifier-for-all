{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# organize imports\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle as cPickle\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 128, 128\n",
    "train_data_dir = \"data/MSTAR_Chips/TRAIN_images\"\n",
    "validation_data_dir = \"data/MSTAR_Chips/TEST_images\"\n",
    "nb_train_samples = 1622\n",
    "nb_validation_samples = 1365 \n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1622 images belonging to 3 classes.\n",
      "Found 1365 images belonging to 3 classes.\n",
      "Found 1365 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\",\n",
    "shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode=None,\n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MSTAR_Chips/TEST_images/bmp2_tank\n",
      "data/MSTAR_Chips/TEST_images/btr70_transport\n",
      "data/MSTAR_Chips/TEST_images/t72_tank\n"
     ]
    }
   ],
   "source": [
    "train_data_dir=\"data/MSTAR_Chips/TEST_images\"\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "image_size=(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "# Load fine tuned pre-train weights\n",
    "model_final.load_weights(\"vgg16_1.h5\")\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 24,156,995\n",
      "Trainable params: 24,044,419\n",
      "Non-trainable params: 112,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDatabase():\n",
    "\n",
    "    numSamplesTrain = float(numImgClass*(float(train)/100))\n",
    "    numSamplesTrain = round(numSamplesTrain)\n",
    "\n",
    "    dataTest = []\n",
    "    labelTest = []\n",
    "    filesTest = []\n",
    "    filesCount = 0\n",
    "    patchesCount = 0\n",
    "\n",
    "    for c in range(1,classes+1):\n",
    "        filesTest.append([])\n",
    "\n",
    "        for s in range(1,numImgClass+1):\n",
    "\n",
    "            if(s < numSamplesTrain+1):\n",
    "                folderTrainTest = 'Treino/'\n",
    "            else:\n",
    "                folderTrainTest = 'Teste/'\n",
    "\n",
    "            for b in range(1,numblock+1):\n",
    "                nameImg = preName + str(c).zfill(5) + sep + str(s) + sep + str(b)\n",
    "                folderClass = preName + str(c).zfill(5) + '/'\n",
    "                fullPathImg = pathImages + folderClass + folderTrainTest + nameImg + imagesFormat\n",
    "                image = plt.imread(fullPathImg)\n",
    "\n",
    "                image = image[np.newaxis]\n",
    "\n",
    "                if(folderTrainTest == 'Treino/'):\n",
    "                    dataTrain.append(image)\n",
    "                    labelTrain.append(c-1)\n",
    "                else:\n",
    "                    dataTest.append(image)\n",
    "                    labelTest.append(c-1)\n",
    "                    filesTest[filesCount].append(patchesCount)\n",
    "                    patchesCount += 1\n",
    "        filesCount+=1\n",
    "\n",
    "    #train\n",
    "    dataTrain = np.array(dataTrain)\n",
    "    labelTrain = np.array(labelTrain)\n",
    "\n",
    "    LUT = np.arange(len(dataTrain), dtype=int)\n",
    "    random.shuffle(LUT)\n",
    "    randomDataTrain = dataTrain[LUT]\n",
    "    randomLabelTrain = labelTrain[LUT]\n",
    "\n",
    "    X_Train = randomDataTrain.astype(\"float32\")/255\n",
    "    Y_Train = np_utils.to_categorical(randomLabelTrain, classes)\n",
    "\n",
    "    #test       \n",
    "    dataTest = np.array(dataTest)\n",
    "    labelTest = np.array(labelTest)\n",
    "    filesTest = np.array(filesTest)\n",
    "\n",
    "    X_Test = dataTest.astype(\"float32\")/255\n",
    "    Y_Test = np_utils.to_categorical(labelTest, classes)\n",
    "\n",
    "    print(\"Number samples train: \",numSamplesTrain*numblock*classes)\n",
    "    print(\"Number samples test: \",(numImgClass-numSamplesTrain)*numblock*classes)       \n",
    "\n",
    "    return X_Train, Y_Train, X_Test, Y_Test, filesTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=1365, callbacks=[<keras.ca..., steps_per_epoch=50, epochs=1, validation_data=<keras.pre...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 123s - loss: 0.2782 - acc: 0.8937 - val_loss: 0.2578 - val_acc: 0.8976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228039e75f8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model according to the conditions  \n",
    "# checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "                            train_generator,\n",
    "                            samples_per_epoch = nb_train_samples,\n",
    "                            epochs = 1,\n",
    "                            validation_data = validation_generator,\n",
    "                            nb_val_samples = nb_validation_samples,\n",
    "                            callbacks = [early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n"
     ]
    }
   ],
   "source": [
    "print(len(test_generator.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model_final.predict_generator(test_generator,1365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(pred,test_generator.classes)\n",
    "print(\"Accuracy :\",accuracy_score(pred,le.inverse_transform(test_labels)))\n",
    "confusion_matrix(pred,le.inverse_transform(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG with imagenet without fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ = applications.VGG16(weights='imagenet',include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext1=Model(input=model_.input, output=model_.get_layer('block5_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext2=Model(input=model_.input, output=model_.get_layer('block4_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext3=Model(input=model_.input, output=model_.get_layer('block3_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext4=Model(input=model_.input, output=model_.get_layer('block2_pool').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Feature extraction from layer block5_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MSTAR_Chips/TRAIN_images/bmp2_tank\n",
      "data/MSTAR_Chips/TRAIN_images/btr70_transport\n",
      "data/MSTAR_Chips/TRAIN_images/t72_tank\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "test_features = []\n",
    "labels   = []\n",
    "test_labels =[]\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext1.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = validation_data_dir + \"/\" + label\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext1.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\ttest_features.append(flat)\n",
    "\t\ttest_labels.append(label)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(labels)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "test_labels=le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(features, le_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      bmp2_tank       0.87      0.92      0.89       550\n",
      "btr70_transport       0.82      0.82      0.82       196\n",
      "       t72_tank       0.97      0.91      0.94       619\n",
      "\n",
      "    avg / total       0.91      0.90      0.90      1365\n",
      "\n",
      "Accuracy : 0.903296703297\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "print(\"Accuracy :\",accuracy_score(le.inverse_transform(preds),le.inverse_transform(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[508,  25,  17],\n",
       "       [ 34, 161,   1],\n",
       "       [ 45,  10, 564]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(le.inverse_transform(preds),le.inverse_transform(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block4_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MSTAR_Chips/TRAIN_images/bmp2_tank\n",
      "data/MSTAR_Chips/TRAIN_images/btr70_transport\n",
      "data/MSTAR_Chips/TRAIN_images/t72_tank\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "test_features = []\n",
    "labels   = []\n",
    "test_labels =[]\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext2.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = validation_data_dir + \"/\" + label\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext2.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\ttest_features.append(flat)\n",
    "\t\ttest_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(labels)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "test_labels=le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(features, le_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      bmp2_tank       0.92      0.99      0.95       547\n",
      "btr70_transport       0.97      0.94      0.95       203\n",
      "       t72_tank       1.00      0.94      0.97       615\n",
      "\n",
      "    avg / total       0.96      0.96      0.96      1365\n",
      "\n",
      "Accuracy : 0.958974358974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[539,   6,   2],\n",
       "       [ 13, 190,   0],\n",
       "       [ 35,   0, 580]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(test_features)\n",
    "print(classification_report(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "print(\"Accuracy :\",accuracy_score(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "confusion_matrix(le.inverse_transform(preds),le.inverse_transform(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block3_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MSTAR_Chips/TRAIN_images/bmp2_tank\n",
      "data/MSTAR_Chips/TRAIN_images/btr70_transport\n",
      "data/MSTAR_Chips/TRAIN_images/t72_tank\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "test_features = []\n",
    "labels   = []\n",
    "test_labels =[]\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext3.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = validation_data_dir + \"/\" + label\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext3.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\ttest_features.append(flat)\n",
    "\t\ttest_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(labels)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "test_labels=le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(features, le_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      bmp2_tank       0.95      1.00      0.98       561\n",
      "btr70_transport       0.99      0.99      0.99       196\n",
      "       t72_tank       1.00      0.96      0.98       608\n",
      "\n",
      "    avg / total       0.98      0.98      0.98      1365\n",
      "\n",
      "Accuracy : 0.979487179487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[560,   1,   0],\n",
       "       [  1, 195,   0],\n",
       "       [ 26,   0, 582]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(test_features)\n",
    "print(classification_report(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "print(\"Accuracy :\",accuracy_score(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "confusion_matrix(le.inverse_transform(preds),le.inverse_transform(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del model,preds,test_features,test_labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block2_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MSTAR_Chips/TRAIN_images/bmp2_tank\n",
      "data/MSTAR_Chips/TRAIN_images/btr70_transport\n",
      "data/MSTAR_Chips/TRAIN_images/t72_tank\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "test_features = []\n",
    "labels   = []\n",
    "test_labels =[]\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext4.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = validation_data_dir + \"/\" + label\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext4.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\ttest_features.append(flat)\n",
    "\t\ttest_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(labels)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "test_labels=le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(features, le_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      bmp2_tank       0.94      0.99      0.97       554\n",
      "btr70_transport       0.99      0.98      0.98       198\n",
      "       t72_tank       1.00      0.95      0.97       613\n",
      "\n",
      "    avg / total       0.97      0.97      0.97      1365\n",
      "\n",
      "Accuracy : 0.971428571429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[551,   2,   1],\n",
       "       [  4, 194,   0],\n",
       "       [ 32,   0, 581]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(test_features)\n",
    "print(classification_report(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "print(\"Accuracy :\",accuracy_score(le.inverse_transform(preds),le.inverse_transform(test_labels)))\n",
    "confusion_matrix(le.inverse_transform(preds),le.inverse_transform(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## With Animal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_animal = applications.VGG16(weights='imagenet',include_top=False, input_shape = (128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_animal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"bl..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext1=Model(input=model_animal.input, output=model_animal.get_layer('block5_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"bl..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext2=Model(input=model_animal.input, output=model_animal.get_layer('block4_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"bl..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext3=Model(input=model_animal.input, output=model_animal.get_layer('block3_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"bl..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "feat_ext4=Model(input=model_animal.input, output=model_animal.get_layer('block2_pool').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block5_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear:105\n",
      "cougar:100\n",
      "cow:97\n",
      "coyote:100\n",
      "deer:100\n",
      "elephant:100\n",
      "giraffe:84\n",
      "goat:99\n",
      "gorilla:83\n",
      "horse:100\n",
      "kangaroo:90\n",
      "leopard:100\n",
      "lion:98\n",
      "panda:97\n",
      "penquin:80\n",
      "sheep:68\n",
      "skunk:62\n",
      "tiger:100\n",
      "zebra:77\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_data_dir='E:/Projects/Sentrana/data/animal_database/train'\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\ti=0\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext1.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)\n",
    "\t\ti=i+1\n",
    "\tprint(\"{}:{}\".format(label,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(y_train)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(y_train)\n",
    "test_labels=le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       bear       0.96      0.79      0.87        34\n",
      "     cougar       0.52      0.46      0.48        35\n",
      "        cow       0.66      0.81      0.72        26\n",
      "     coyote       0.82      0.75      0.78        36\n",
      "       deer       0.79      0.74      0.77        42\n",
      "   elephant       0.94      0.81      0.87        36\n",
      "    giraffe       0.88      0.91      0.89        32\n",
      "       goat       0.81      0.61      0.69        41\n",
      "    gorilla       0.81      0.93      0.86        27\n",
      "      horse       0.97      1.00      0.98        30\n",
      "   kangaroo       0.78      0.84      0.81        25\n",
      "    leopard       0.89      0.80      0.84        30\n",
      "       lion       0.78      0.86      0.82        37\n",
      "      panda       0.90      0.96      0.93        27\n",
      "    penquin       0.89      0.89      0.89        28\n",
      "      sheep       0.54      0.72      0.62        18\n",
      "      skunk       0.78      0.93      0.85        15\n",
      "      tiger       0.84      0.97      0.90        33\n",
      "      zebra       1.00      1.00      1.00        23\n",
      "\n",
      "avg / total       0.82      0.82      0.82       575\n",
      "\n",
      "Accuracy : 0.817391304348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27,  1,  1,  1,  0,  0,  0,  0,  2,  0,  1,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0],\n",
       "       [ 0, 16,  3,  0,  4,  0,  0,  1,  0,  0,  1,  2,  5,  0,  2,  0,  0,\n",
       "         1,  0],\n",
       "       [ 0,  0, 21,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  2,  0,\n",
       "         1,  0],\n",
       "       [ 0,  2,  0, 27,  2,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         2,  0],\n",
       "       [ 0,  3,  1,  3, 31,  1,  1,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  0,  2,  0,  1, 29,  1,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0, 29,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  3,  2,  1,  0,  0,  0, 25,  1,  0,  0,  0,  2,  0,  1,  6,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 25,  0,  0,  0,  0,  0,  0,  0,  2,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 30,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0, 21,  0,  1,  0,  0,  1,  0,\n",
       "         0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  0,  1,  0,  0,  1,  0, 24,  0,  0,  0,  0,  0,\n",
       "         2,  0],\n",
       "       [ 0,  2,  0,  0,  1,  0,  0,  0,  0,  0,  2,  0, 32,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 26,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0, 25,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  2,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0, 13,  1,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0, 14,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "        32,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0, 23]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(preds,y_test))\n",
    "print(\"Accuracy :\",model.score(X_test,y_test))\n",
    "confusion_matrix(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting better accuracy with 224 * 224 around 88 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block4_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Projects/Sentrana/data/animal_database/train/bear\n",
      "E:/Projects/Sentrana/data/animal_database/train/cougar\n",
      "E:/Projects/Sentrana/data/animal_database/train/cow\n",
      "E:/Projects/Sentrana/data/animal_database/train/coyote\n",
      "E:/Projects/Sentrana/data/animal_database/train/deer\n",
      "E:/Projects/Sentrana/data/animal_database/train/elephant\n",
      "E:/Projects/Sentrana/data/animal_database/train/giraffe\n",
      "E:/Projects/Sentrana/data/animal_database/train/goat\n",
      "E:/Projects/Sentrana/data/animal_database/train/gorilla\n",
      "E:/Projects/Sentrana/data/animal_database/train/horse\n",
      "E:/Projects/Sentrana/data/animal_database/train/kangaroo\n",
      "E:/Projects/Sentrana/data/animal_database/train/leopard\n",
      "E:/Projects/Sentrana/data/animal_database/train/lion\n",
      "E:/Projects/Sentrana/data/animal_database/train/panda\n",
      "E:/Projects/Sentrana/data/animal_database/train/penquin\n",
      "E:/Projects/Sentrana/data/animal_database/train/sheep\n",
      "E:/Projects/Sentrana/data/animal_database/train/skunk\n",
      "E:/Projects/Sentrana/data/animal_database/train/tiger\n",
      "E:/Projects/Sentrana/data/animal_database/train/zebra\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_data_dir='E:/Projects/Sentrana/data/animal_database/train'\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext2.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(y_train)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(y_train)\n",
    "test_labels=le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       bear       0.89      0.83      0.86        30\n",
      "     cougar       0.55      0.53      0.54        32\n",
      "        cow       0.62      0.61      0.62        33\n",
      "     coyote       0.76      0.64      0.69        39\n",
      "       deer       0.72      0.82      0.77        34\n",
      "   elephant       0.94      0.88      0.91        33\n",
      "    giraffe       0.85      0.82      0.84        34\n",
      "       goat       0.81      0.66      0.72        38\n",
      "    gorilla       0.81      0.81      0.81        31\n",
      "      horse       1.00      0.82      0.90        38\n",
      "   kangaroo       0.59      0.62      0.60        26\n",
      "    leopard       0.89      0.83      0.86        29\n",
      "       lion       0.78      0.86      0.82        37\n",
      "      panda       0.83      0.80      0.81        30\n",
      "    penquin       0.68      0.83      0.75        23\n",
      "      sheep       0.42      0.62      0.50        16\n",
      "      skunk       0.67      0.92      0.77        13\n",
      "      tiger       0.84      0.89      0.86        36\n",
      "      zebra       0.96      0.96      0.96        23\n",
      "\n",
      "avg / total       0.78      0.77      0.77       575\n",
      "\n",
      "Accuracy : 0.772173913043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25,  0,  1,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  1,\n",
       "         0,  0],\n",
       "       [ 0, 17,  2,  1,  2,  0,  0,  1,  0,  0,  1,  2,  4,  1,  0,  0,  0,\n",
       "         1,  0],\n",
       "       [ 0,  0, 20,  0,  0,  1,  0,  1,  1,  0,  5,  0,  0,  0,  0,  5,  0,\n",
       "         0,  0],\n",
       "       [ 0,  5,  0, 25,  3,  0,  0,  1,  0,  0,  1,  0,  1,  0,  0,  1,  0,\n",
       "         2,  0],\n",
       "       [ 0,  2,  1,  2, 28,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  1,  1,  0,  0, 29,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  1, 28,  0,  0,  0,  0,  0,  0,  1,  0,  2,  0,\n",
       "         0,  1],\n",
       "       [ 0,  3,  2,  1,  3,  0,  0, 25,  0,  0,  1,  0,  1,  0,  0,  1,  0,\n",
       "         1,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0, 25,  0,  0,  0,  0,  0,  3,  0,  2,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  1,  2,  0,  0,  0,  0, 31,  1,  0,  0,  0,  0,  2,  0,\n",
       "         0,  0],\n",
       "       [ 0,  2,  1,  1,  0,  0,  1,  1,  0,  0, 16,  1,  0,  0,  1,  2,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0, 24,  0,  0,  1,  1,  0,\n",
       "         1,  0],\n",
       "       [ 1,  1,  0,  0,  0,  0,  1,  0,  0,  0,  2,  0, 32,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 24,  4,  0,  2,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  1, 19,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  0,  1,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  1,  0, 10,  1,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 12,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,\n",
       "        32,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         1, 22]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(preds,y_test))\n",
    "print(\"Accuracy :\",model.score(X_test,y_test))\n",
    "confusion_matrix(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     precision    recall  f1-score   support\\n\\n       bear       0.89      0.78      0.83        32\\n     cougar       0.52      0.59      0.55        27\\n        cow       0.59      0.63      0.61        30\\n     coyote       0.73      0.69      0.71        35\\n       deer       0.79      0.84      0.82        37\\n   elephant       0.94      0.88      0.91        33\\n    giraffe       0.82      0.90      0.86        30\\n       goat       0.87      0.71      0.78        38\\n    gorilla       0.71      0.88      0.79        25\\n      horse       1.00      0.69      0.82        45\\n   kangaroo       0.52      0.70      0.60        20\\n    leopard       0.93      0.81      0.86        31\\n       lion       0.90      0.86      0.88        43\\n      panda       0.90      0.72      0.80        36\\n    penquin       0.64      0.69      0.67        26\\n      sheep       0.29      0.58      0.39        12\\n      skunk       0.78      0.82      0.80        17\\n      tiger       0.87      0.97      0.92        34\\n      zebra       1.00      0.96      0.98        24\\n\\navg / total       0.81      0.78      0.79       575\\n\\nAccuracy : 0.779130434783\\nOut[93]:\\narray([[25,  0,  1,  1,  0,  0,  0,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,\\n         0,  0],\\n       [ 0, 16,  0,  2,  3,  0,  0,  1,  0,  0,  0,  1,  2,  1,  0,  0,  0,\\n         1,  0],\\n       [ 0,  0, 19,  0,  0,  1,  0,  1,  1,  0,  2,  0,  0,  0,  0,  6,  0,\\n         0,  0],\\n       [ 0,  5,  0, 24,  1,  0,  0,  0,  0,  0,  2,  0,  1,  0,  0,  1,  0,\\n         1,  0],\\n       [ 0,  1,  1,  3, 31,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n         0,  0],\\n       [ 0,  1,  0,  0,  0, 29,  1,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\\n         0,  0],\\n       [ 0,  0,  0,  0,  0,  1, 27,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,\\n         0,  0],\\n       [ 0,  4,  1,  1,  1,  0,  1, 27,  0,  0,  1,  0,  0,  0,  1,  1,  0,\\n         0,  0],\\n       [ 1,  0,  0,  0,  0,  0,  0,  0, 22,  0,  0,  0,  0,  0,  2,  0,  0,\\n         0,  0],\\n       [ 0,  1,  3,  1,  1,  0,  0,  1,  0, 31,  2,  0,  0,  0,  0,  5,  0,\\n         0,  0],\\n       [ 0,  0,  3,  0,  1,  0,  0,  1,  0,  0, 14,  0,  0,  0,  1,  0,  0,\\n         0,  0],\\n       [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1, 25,  0,  0,  1,  1,  0,\\n         2,  0],\\n       [ 1,  1,  0,  0,  1,  0,  1,  0,  0,  0,  1,  0, 37,  0,  1,  0,  0,\\n         0,  0],\\n       [ 0,  2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0, 26,  3,  1,  2,\\n         0,  0],\\n       [ 0,  0,  2,  1,  0,  0,  1,  0,  2,  0,  1,  0,  0,  1, 18,  0,  0,\\n         0,  0],\\n       [ 1,  0,  2,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  7,  1,\\n         0,  0],\\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  1, 14,\\n         0,  0],\\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\\n        33,  0],\\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n         1, 23]])\\n         \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''     precision    recall  f1-score   support\n",
    "\n",
    "       bear       0.89      0.78      0.83        32\n",
    "     cougar       0.52      0.59      0.55        27\n",
    "        cow       0.59      0.63      0.61        30\n",
    "     coyote       0.73      0.69      0.71        35\n",
    "       deer       0.79      0.84      0.82        37\n",
    "   elephant       0.94      0.88      0.91        33\n",
    "    giraffe       0.82      0.90      0.86        30\n",
    "       goat       0.87      0.71      0.78        38\n",
    "    gorilla       0.71      0.88      0.79        25\n",
    "      horse       1.00      0.69      0.82        45\n",
    "   kangaroo       0.52      0.70      0.60        20\n",
    "    leopard       0.93      0.81      0.86        31\n",
    "       lion       0.90      0.86      0.88        43\n",
    "      panda       0.90      0.72      0.80        36\n",
    "    penquin       0.64      0.69      0.67        26\n",
    "      sheep       0.29      0.58      0.39        12\n",
    "      skunk       0.78      0.82      0.80        17\n",
    "      tiger       0.87      0.97      0.92        34\n",
    "      zebra       1.00      0.96      0.98        24\n",
    "\n",
    "avg / total       0.81      0.78      0.79       575\n",
    "\n",
    "Accuracy : 0.779130434783\n",
    "Out[93]:\n",
    "array([[25,  0,  1,  1,  0,  0,  0,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,\n",
    "         0,  0],\n",
    "       [ 0, 16,  0,  2,  3,  0,  0,  1,  0,  0,  0,  1,  2,  1,  0,  0,  0,\n",
    "         1,  0],\n",
    "       [ 0,  0, 19,  0,  0,  1,  0,  1,  1,  0,  2,  0,  0,  0,  0,  6,  0,\n",
    "         0,  0],\n",
    "       [ 0,  5,  0, 24,  1,  0,  0,  0,  0,  0,  2,  0,  1,  0,  0,  1,  0,\n",
    "         1,  0],\n",
    "       [ 0,  1,  1,  3, 31,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  1,  0,  0,  0, 29,  1,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  1, 27,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,\n",
    "         0,  0],\n",
    "       [ 0,  4,  1,  1,  1,  0,  1, 27,  0,  0,  1,  0,  0,  0,  1,  1,  0,\n",
    "         0,  0],\n",
    "       [ 1,  0,  0,  0,  0,  0,  0,  0, 22,  0,  0,  0,  0,  0,  2,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  1,  3,  1,  1,  0,  0,  1,  0, 31,  2,  0,  0,  0,  0,  5,  0,\n",
    "         0,  0],\n",
    "       [ 0,  0,  3,  0,  1,  0,  0,  1,  0,  0, 14,  0,  0,  0,  1,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1, 25,  0,  0,  1,  1,  0,\n",
    "         2,  0],\n",
    "       [ 1,  1,  0,  0,  1,  0,  1,  0,  0,  0,  1,  0, 37,  0,  1,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0, 26,  3,  1,  2,\n",
    "         0,  0],\n",
    "       [ 0,  0,  2,  1,  0,  0,  1,  0,  2,  0,  1,  0,  0,  1, 18,  0,  0,\n",
    "         0,  0],\n",
    "       [ 1,  0,  2,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  7,  1,\n",
    "         0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  1, 14,\n",
    "         0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
    "        33,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         1, 23]])\n",
    "         \n",
    "'''\n",
    "# result with 224*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model,X_train, X_test, y_train, y_test,features,labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block3_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Projects/Sentrana/data/animal_database/train/bear\n",
      "E:/Projects/Sentrana/data/animal_database/train/cougar\n",
      "E:/Projects/Sentrana/data/animal_database/train/cow\n",
      "E:/Projects/Sentrana/data/animal_database/train/coyote\n",
      "E:/Projects/Sentrana/data/animal_database/train/deer\n",
      "E:/Projects/Sentrana/data/animal_database/train/elephant\n",
      "E:/Projects/Sentrana/data/animal_database/train/giraffe\n",
      "E:/Projects/Sentrana/data/animal_database/train/goat\n",
      "E:/Projects/Sentrana/data/animal_database/train/gorilla\n",
      "E:/Projects/Sentrana/data/animal_database/train/horse\n",
      "E:/Projects/Sentrana/data/animal_database/train/kangaroo\n",
      "E:/Projects/Sentrana/data/animal_database/train/leopard\n",
      "E:/Projects/Sentrana/data/animal_database/train/lion\n",
      "E:/Projects/Sentrana/data/animal_database/train/panda\n",
      "E:/Projects/Sentrana/data/animal_database/train/penquin\n",
      "E:/Projects/Sentrana/data/animal_database/train/sheep\n",
      "E:/Projects/Sentrana/data/animal_database/train/skunk\n",
      "E:/Projects/Sentrana/data/animal_database/train/tiger\n",
      "E:/Projects/Sentrana/data/animal_database/train/zebra\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_data_dir='E:/Projects/Sentrana/data/animal_database/train'\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext3.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(y_train)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(y_train)\n",
    "test_labels=le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       bear       0.82      0.64      0.72        36\n",
      "     cougar       0.35      0.42      0.39        26\n",
      "        cow       0.50      0.55      0.52        29\n",
      "     coyote       0.61      0.61      0.61        33\n",
      "       deer       0.56      0.71      0.63        31\n",
      "   elephant       0.90      0.76      0.82        37\n",
      "    giraffe       0.67      0.85      0.75        26\n",
      "       goat       0.87      0.63      0.73        43\n",
      "    gorilla       0.61      0.70      0.66        27\n",
      "      horse       1.00      0.70      0.83        44\n",
      "   kangaroo       0.37      0.36      0.36        28\n",
      "    leopard       0.81      0.65      0.72        34\n",
      "       lion       0.68      0.85      0.76        33\n",
      "      panda       0.72      0.70      0.71        30\n",
      "    penquin       0.54      0.62      0.58        24\n",
      "      sheep       0.17      0.29      0.21        14\n",
      "      skunk       0.61      0.85      0.71        13\n",
      "      tiger       0.76      0.71      0.73        41\n",
      "      zebra       0.96      0.85      0.90        26\n",
      "\n",
      "avg / total       0.70      0.66      0.67       575\n",
      "\n",
      "Accuracy : 0.662608695652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[23,  0,  0,  1,  1,  0,  1,  1,  1,  0,  1,  0,  1,  2,  0,  2,  2,\n",
       "         0,  0],\n",
       "       [ 1, 11,  1,  2,  3,  0,  0,  1,  0,  0,  0,  1,  5,  1,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0, 16,  1,  1,  1,  0,  1,  0,  0,  2,  0,  0,  2,  0,  5,  0,\n",
       "         0,  0],\n",
       "       [ 0,  6,  0, 20,  3,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,\n",
       "         2,  0],\n",
       "       [ 0,  1,  0,  4, 22,  0,  1,  0,  0,  0,  1,  0,  0,  1,  1,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  2,  1,  0,  0, 28,  2,  1,  1,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  1, 22,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "         0,  1],\n",
       "       [ 0,  5,  2,  0,  2,  0,  0, 27,  0,  0,  1,  0,  0,  0,  2,  3,  0,\n",
       "         1,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  1,  0, 19,  0,  2,  0,  0,  0,  4,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  1,  1,  2,  2,  0,  0,  0,  0, 31,  2,  0,  0,  0,  0,  4,  0,\n",
       "         1,  0],\n",
       "       [ 0,  2,  4,  1,  0,  1,  2,  0,  2,  0, 10,  0,  2,  0,  1,  3,  0,\n",
       "         0,  0],\n",
       "       [ 1,  3,  0,  0,  0,  0,  1,  0,  0,  0,  1, 22,  2,  0,  1,  0,  0,\n",
       "         3,  0],\n",
       "       [ 1,  0,  0,  0,  2,  0,  1,  0,  0,  0,  1,  0, 28,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0, 21,  3,  0,  3,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  1,  0,  0,  0,  0,  4,  0,  1,  0,  0,  0, 15,  2,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  3,  0,  0,  0,  1,  0,  1,  0,  2,  0,  0,  1,  1,  4,  1,\n",
       "         0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0, 11,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  1,  3,  0,  0,  0,  0,  0,  1,  4,  2,  0,  0,  0,  0,\n",
       "        29,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         2, 22]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(preds,y_test))\n",
    "print(\"Accuracy :\",model.score(X_test,y_test))\n",
    "confusion_matrix(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    precision    recall  f1-score   support\\n\\n       bear       0.93      0.74      0.83        35\\n     cougar       0.32      0.59      0.42        17\\n        cow       0.59      0.54      0.57        35\\n     coyote       0.67      0.58      0.62        38\\n       deer       0.54      0.81      0.65        26\\n   elephant       0.90      0.80      0.85        35\\n    giraffe       0.76      0.83      0.79        30\\n       goat       0.84      0.55      0.67        47\\n    gorilla       0.61      0.66      0.63        29\\n      horse       1.00      0.67      0.81        46\\n   kangaroo       0.30      0.36      0.33        22\\n    leopard       0.89      0.77      0.83        31\\n       lion       0.68      0.80      0.74        35\\n      panda       0.69      0.71      0.70        28\\n    penquin       0.64      0.55      0.59        33\\n      sheep       0.21      0.45      0.29        11\\n      skunk       0.56      0.67      0.61        15\\n      tiger       0.79      0.79      0.79        38\\n      zebra       0.96      0.92      0.94        24\\n\\navg / total       0.73      0.68      0.69       575\\n\\nAccuracy : 0.681739130435\\nOut[99]:\\narray([[26,  0,  0,  1,  2,  0,  1,  0,  0,  0,  2,  0,  0,  0,  1,  0,  2,\\n         0,  0],\\n       [ 0, 10,  0,  1,  1,  0,  0,  1,  0,  0,  0,  1,  2,  1,  0,  0,  0,\\n         0,  0],\\n       [ 0,  0, 19,  1,  1,  1,  2,  0,  2,  0,  2,  0,  0,  0,  1,  6,  0,\\n         0,  0],\\n       [ 0,  5,  0, 22,  5,  0,  0,  1,  1,  0,  2,  0,  1,  0,  0,  0,  0,\\n         1,  0],\\n       [ 0,  1,  0,  1, 21,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  0,\\n         0,  0],\\n       [ 0,  2,  0,  0,  0, 28,  1,  2,  0,  0,  0,  0,  2,  0,  0,  0,  0,\\n         0,  0],\\n       [ 0,  0,  0,  0,  0,  1, 25,  0,  0,  0,  1,  0,  1,  1,  0,  1,  0,\\n         0,  0],\\n       [ 0,  8,  1,  1,  3,  0,  0, 26,  0,  0,  2,  0,  2,  0,  1,  2,  0,\\n         1,  0],\\n       [ 1,  1,  0,  0,  0,  0,  0,  0, 19,  0,  2,  0,  0,  3,  3,  0,  0,\\n         0,  0],\\n       [ 0,  1,  2,  2,  1,  0,  0,  0,  0, 31,  2,  0,  0,  0,  0,  4,  0,\\n         3,  0],\\n       [ 0,  1,  3,  0,  0,  1,  2,  0,  1,  0,  8,  0,  2,  1,  0,  3,  0,\\n         0,  0],\\n       [ 0,  2,  0,  2,  0,  0,  0,  0,  0,  0,  1, 24,  0,  0,  1,  0,  0,\\n         1,  0],\\n       [ 1,  0,  0,  1,  2,  0,  1,  0,  0,  0,  2,  0, 28,  0,  0,  0,  0,\\n         0,  0],\\n       [ 0,  0,  1,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0, 20,  2,  0,  3,\\n         0,  0],\\n       [ 0,  0,  3,  0,  0,  0,  0,  1,  5,  0,  1,  0,  0,  1, 18,  2,  1,\\n         0,  1],\\n       [ 0,  0,  2,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  5,  2,\\n         0,  0],\\n       [ 0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  1,  0,  1, 10,\\n         0,  0],\\n       [ 0,  0,  0,  1,  3,  0,  0,  0,  0,  0,  0,  2,  2,  0,  0,  0,  0,\\n        30,  0],\\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n         2, 22]])\\n        '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### With 224 * 224\n",
    "'''    precision    recall  f1-score   support\n",
    "\n",
    "       bear       0.93      0.74      0.83        35\n",
    "     cougar       0.32      0.59      0.42        17\n",
    "        cow       0.59      0.54      0.57        35\n",
    "     coyote       0.67      0.58      0.62        38\n",
    "       deer       0.54      0.81      0.65        26\n",
    "   elephant       0.90      0.80      0.85        35\n",
    "    giraffe       0.76      0.83      0.79        30\n",
    "       goat       0.84      0.55      0.67        47\n",
    "    gorilla       0.61      0.66      0.63        29\n",
    "      horse       1.00      0.67      0.81        46\n",
    "   kangaroo       0.30      0.36      0.33        22\n",
    "    leopard       0.89      0.77      0.83        31\n",
    "       lion       0.68      0.80      0.74        35\n",
    "      panda       0.69      0.71      0.70        28\n",
    "    penquin       0.64      0.55      0.59        33\n",
    "      sheep       0.21      0.45      0.29        11\n",
    "      skunk       0.56      0.67      0.61        15\n",
    "      tiger       0.79      0.79      0.79        38\n",
    "      zebra       0.96      0.92      0.94        24\n",
    "\n",
    "avg / total       0.73      0.68      0.69       575\n",
    "\n",
    "Accuracy : 0.681739130435\n",
    "Out[99]:\n",
    "array([[26,  0,  0,  1,  2,  0,  1,  0,  0,  0,  2,  0,  0,  0,  1,  0,  2,\n",
    "         0,  0],\n",
    "       [ 0, 10,  0,  1,  1,  0,  0,  1,  0,  0,  0,  1,  2,  1,  0,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  0, 19,  1,  1,  1,  2,  0,  2,  0,  2,  0,  0,  0,  1,  6,  0,\n",
    "         0,  0],\n",
    "       [ 0,  5,  0, 22,  5,  0,  0,  1,  1,  0,  2,  0,  1,  0,  0,  0,  0,\n",
    "         1,  0],\n",
    "       [ 0,  1,  0,  1, 21,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  2,  0,  0,  0, 28,  1,  2,  0,  0,  0,  0,  2,  0,  0,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  1, 25,  0,  0,  0,  1,  0,  1,  1,  0,  1,  0,\n",
    "         0,  0],\n",
    "       [ 0,  8,  1,  1,  3,  0,  0, 26,  0,  0,  2,  0,  2,  0,  1,  2,  0,\n",
    "         1,  0],\n",
    "       [ 1,  1,  0,  0,  0,  0,  0,  0, 19,  0,  2,  0,  0,  3,  3,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  1,  2,  2,  1,  0,  0,  0,  0, 31,  2,  0,  0,  0,  0,  4,  0,\n",
    "         3,  0],\n",
    "       [ 0,  1,  3,  0,  0,  1,  2,  0,  1,  0,  8,  0,  2,  1,  0,  3,  0,\n",
    "         0,  0],\n",
    "       [ 0,  2,  0,  2,  0,  0,  0,  0,  0,  0,  1, 24,  0,  0,  1,  0,  0,\n",
    "         1,  0],\n",
    "       [ 1,  0,  0,  1,  2,  0,  1,  0,  0,  0,  2,  0, 28,  0,  0,  0,  0,\n",
    "         0,  0],\n",
    "       [ 0,  0,  1,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0, 20,  2,  0,  3,\n",
    "         0,  0],\n",
    "       [ 0,  0,  3,  0,  0,  0,  0,  1,  5,  0,  1,  0,  0,  1, 18,  2,  1,\n",
    "         0,  1],\n",
    "       [ 0,  0,  2,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  5,  2,\n",
    "         0,  0],\n",
    "       [ 0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  1,  0,  1, 10,\n",
    "         0,  0],\n",
    "       [ 0,  0,  0,  1,  3,  0,  0,  0,  0,  0,  0,  2,  2,  0,  0,  0,  0,\n",
    "        30,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         2, 22]])\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model,X_train, X_test, y_train, y_test,features,labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from layer block2_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Projects/Sentrana/data/animal_database/train/bear\n",
      "E:/Projects/Sentrana/data/animal_database/train/cougar\n",
      "E:/Projects/Sentrana/data/animal_database/train/cow\n",
      "E:/Projects/Sentrana/data/animal_database/train/coyote\n",
      "E:/Projects/Sentrana/data/animal_database/train/deer\n",
      "E:/Projects/Sentrana/data/animal_database/train/elephant\n",
      "E:/Projects/Sentrana/data/animal_database/train/giraffe\n",
      "E:/Projects/Sentrana/data/animal_database/train/goat\n",
      "E:/Projects/Sentrana/data/animal_database/train/gorilla\n",
      "E:/Projects/Sentrana/data/animal_database/train/horse\n",
      "E:/Projects/Sentrana/data/animal_database/train/kangaroo\n",
      "E:/Projects/Sentrana/data/animal_database/train/leopard\n",
      "E:/Projects/Sentrana/data/animal_database/train/lion\n",
      "E:/Projects/Sentrana/data/animal_database/train/panda\n",
      "E:/Projects/Sentrana/data/animal_database/train/penquin\n",
      "E:/Projects/Sentrana/data/animal_database/train/sheep\n",
      "E:/Projects/Sentrana/data/animal_database/train/skunk\n",
      "E:/Projects/Sentrana/data/animal_database/train/tiger\n",
      "E:/Projects/Sentrana/data/animal_database/train/zebra\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_data_dir='E:/Projects/Sentrana/data/animal_database/train'\n",
    "train_labels = os.listdir(train_data_dir)\n",
    "\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "image_size=(128,128)\n",
    "# loop over all the labels in the folder\n",
    "for label in train_labels:\n",
    "\tcur_path = train_data_dir + \"/\" + label\n",
    "\tprint(cur_path)\n",
    "\tfor image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\timg = image.load_img(image_path, target_size=image_size)\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\tfeature = feat_ext4.predict(x)\n",
    "\t\tflat = feature.flatten()\n",
    "\t\tfeatures.append(flat)\n",
    "\t\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "targetNames = np.unique(y_train)\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(y_train)\n",
    "test_labels=le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2017, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression as the model\n",
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       bear       0.79      0.63      0.70        35\n",
      "     cougar       0.19      0.32      0.24        19\n",
      "        cow       0.41      0.39      0.40        33\n",
      "     coyote       0.48      0.41      0.44        39\n",
      "       deer       0.21      0.40      0.27        20\n",
      "   elephant       0.74      0.61      0.67        38\n",
      "    giraffe       0.48      0.73      0.58        22\n",
      "       goat       0.52      0.40      0.45        40\n",
      "    gorilla       0.42      0.48      0.45        27\n",
      "      horse       1.00      0.58      0.74        53\n",
      "   kangaroo       0.19      0.16      0.17        32\n",
      "    leopard       0.81      0.54      0.65        41\n",
      "       lion       0.59      0.63      0.61        38\n",
      "      panda       0.59      0.55      0.57        31\n",
      "    penquin       0.32      0.36      0.34        25\n",
      "      sheep       0.21      0.56      0.30         9\n",
      "      skunk       0.44      0.67      0.53        12\n",
      "      tiger       0.53      0.57      0.55        35\n",
      "      zebra       0.91      0.81      0.86        26\n",
      "\n",
      "avg / total       0.57      0.51      0.53       575\n",
      "\n",
      "Accuracy : 0.513043478261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22,  0,  0,  1,  2,  0,  0,  0,  3,  0,  2,  1,  1,  0,  1,  0,  1,\n",
       "         1,  0],\n",
       "       [ 0,  6,  0,  2,  1,  0,  0,  1,  0,  0,  2,  1,  3,  1,  1,  0,  0,\n",
       "         1,  0],\n",
       "       [ 0,  0, 13,  0,  1,  3,  2,  2,  2,  0,  1,  0,  0,  1,  1,  7,  0,\n",
       "         0,  0],\n",
       "       [ 1,  5,  1, 16,  6,  0,  0,  2,  2,  0,  1,  0,  0,  0,  2,  0,  0,\n",
       "         3,  0],\n",
       "       [ 0,  2,  0,  1,  8,  1,  0,  2,  0,  0,  0,  0,  1,  2,  1,  0,  0,\n",
       "         2,  0],\n",
       "       [ 2,  2,  2,  0,  3, 23,  3,  0,  0,  0,  0,  0,  1,  1,  0,  0,  1,\n",
       "         0,  0],\n",
       "       [ 1,  0,  0,  0,  1,  1, 16,  0,  0,  0,  1,  1,  0,  0,  0,  1,  0,\n",
       "         0,  0],\n",
       "       [ 0,  8,  1,  1,  3,  0,  0, 16,  0,  0,  2,  0,  2,  1,  3,  2,  1,\n",
       "         0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0, 13,  0,  4,  0,  0,  4,  4,  1,  0,\n",
       "         0,  0],\n",
       "       [ 1,  1,  2,  3,  3,  0,  0,  0,  0, 31,  3,  0,  0,  0,  0,  4,  1,\n",
       "         4,  0],\n",
       "       [ 0,  2,  4,  1,  1,  1,  2,  1,  1,  0,  5,  0,  6,  0,  2,  3,  1,\n",
       "         0,  2],\n",
       "       [ 0,  3,  0,  0,  1,  0,  4,  1,  0,  0,  3, 22,  1,  0,  1,  0,  0,\n",
       "         5,  0],\n",
       "       [ 0,  1,  2,  2,  2,  2,  1,  2,  0,  0,  1,  0, 24,  0,  0,  0,  0,\n",
       "         1,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  1,  2,  2,  0,  0,  0,  0, 17,  3,  0,  5,\n",
       "         0,  0],\n",
       "       [ 0,  1,  2,  1,  3,  0,  0,  0,  6,  0,  1,  0,  0,  1,  9,  1,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  1,  0,  1,  0,  0,  5,  0,\n",
       "         0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  1,  0,  0,  8,\n",
       "         0,  0],\n",
       "       [ 0,  0,  2,  5,  3,  0,  2,  0,  0,  0,  0,  2,  1,  0,  0,  0,  0,\n",
       "        20,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         1, 21]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model of test data\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(preds,y_test))\n",
    "print(\"Accuracy :\",model.score(X_test,y_test))\n",
    "confusion_matrix(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model,X_train, X_test, y_train, y_test,features,labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune output with different blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ = applications.VGG16(weights='imagenet',include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With block4_pool and MSTAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x000001C1B1FE39B0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B1FE3DA0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B1FE3C88>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C1B1FE3D30>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B31357B8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B3132518>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C1B31C6898>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B31E1438>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B31EAC88>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B32077F0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C1B3211B70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B325BF60>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B326EE10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001C1B328BB38>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001C1B32787B8>\n"
     ]
    }
   ],
   "source": [
    "for layer in model_.layers[:15]:\n",
    "    print(layer)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.MaxPooling2D at 0x1c1b32787b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.layers[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block1_conv1',\n",
       " 'block1_conv2',\n",
       " 'block1_pool',\n",
       " 'block2_conv1',\n",
       " 'block2_conv2',\n",
       " 'block2_pool',\n",
       " 'block3_conv1',\n",
       " 'block3_conv2',\n",
       " 'block3_conv3',\n",
       " 'block3_pool',\n",
       " 'block4_conv1',\n",
       " 'block4_conv2',\n",
       " 'block4_conv3',\n",
       " 'block4_pool',\n",
       " 'block5_conv1',\n",
       " 'block5_conv2',\n",
       " 'block5_conv3',\n",
       " 'block5_pool',\n",
       " 'dense_1',\n",
       " 'dense_2',\n",
       " 'dense_3',\n",
       " 'dropout_1',\n",
       " 'flatten_1',\n",
       " 'input_1']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "weights_path = 'vgg16_1.h5' # ('https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5)\n",
    "f = h5py.File(weights_path)\n",
    "list(f[\"model_weights\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#Adding custom Layers \n",
    "x = model_.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model_.input, output = predictions)\n",
    "# Load fine tuned pre-train weights\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 24,156,995\n",
      "Trainable params: 16,521,731\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\r",
      " 1/50 [..............................] - ETA: 8s - loss: 1.0877 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., epochs=50, callbacks=[<keras.ca..., steps_per_epoch=50, validation_steps=1365)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 [============================>.] - ETA: 0s - loss: 1.0106 - acc: 0.4748"
     ]
    }
   ],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_block_4.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "                            train_generator,\n",
    "                            samples_per_epoch = nb_train_samples,\n",
    "                            epochs = 50,\n",
    "                            validation_data = validation_generator,\n",
    "                            nb_val_samples = nb_validation_samples,\n",
    "                            callbacks = [checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.save_weights(\"vgg16_block_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Build the network \n",
    "# img_input = Input(shape=(256, 256, 3))\n",
    "# x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "# x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "# x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "# x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "# x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "# x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# model = Model(input = img_input, output = x)\n",
    "\n",
    "# model.summary()\n",
    "\"\"\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
    "=================================================================\n",
    "Total params: 260,160.0\n",
    "Trainable params: 260,160.0\n",
    "Non-trainable params: 0.0\n",
    "\"\"\"\n",
    "\n",
    "# layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "# [layer.name for layer in model.layers]\n",
    "\"\"\"\n",
    "['input_1',\n",
    " 'block1_conv1',\n",
    " 'block1_conv2',\n",
    " 'block1_pool',\n",
    " 'block2_conv1',\n",
    " 'block2_conv2',\n",
    " 'block2_pool']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# list all the layer names which are in the model.\n",
    "# layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Here we are extracting model_weights for each and every layer from the .h5 file\n",
    ">>> f[\"model_weights\"][\"block1_conv1\"].attrs[\"weight_names\"]\n",
    "array([b'block1_conv1/kernel:0', b'block1_conv1/bias:0'], \n",
    "      dtype='|S21')\n",
    "# we are assiging this array to weight_names below \n",
    ">>> f[\"model_weights\"][\"block1_conv1\"][\"block1_conv1/kernel:0]\n",
    "<HDF5 dataset \"kernel:0\": shape (3, 3, 3, 64), type \"<f4\">\n",
    "# The list comprehension (weights) stores these two weights and bias of both the layers \n",
    ">>>layer_names.index(\"block1_conv1\")\n",
    "1\n",
    ">>> model.layers[1].set_weights(weights)\n",
    "# This will set the weights for that particular layer.\n",
    "With a for loop we can set_weights for the entire network.\n",
    "\"\"\"\n",
    "# for i in layer_dict.keys():\n",
    "#    weight_names = f[\"model_weights\"][i].attrs[\"weight_names\"]\n",
    "#    weights = [f[\"model_weights\"][i][j] for j in weight_names]\n",
    "#    index = layer_names.index(i)\n",
    "#    model.layers[index].set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
